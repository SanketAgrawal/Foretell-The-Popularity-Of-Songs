{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:39:03.271227Z",
     "start_time": "2020-01-19T07:39:01.562559Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import catboost\n",
    "import lightgbm as lgb\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:39:03.622154Z",
     "start_time": "2020-01-19T07:39:03.273807Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('Data_Train.csv')\n",
    "test_data = pd.read_csv('Data_Test.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the shape of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:39:03.636051Z",
     "start_time": "2020-01-19T07:39:03.625872Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a label encoder for the column Genre. This label encoder will then be used to transform the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:39:03.787060Z",
     "start_time": "2020-01-19T07:39:03.639279Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.Genre = train_data.Genre.astype('category')\n",
    "le_genre = preprocessing.LabelEncoder()\n",
    "le_genre.fit(train_data.Genre)\n",
    "train_data.Genre = le_genre.transform(train_data.Genre)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a label encoder for the column Name. This label encoder will then be used to transform the same column in the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:39:04.140727Z",
     "start_time": "2020-01-19T07:39:03.789903Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.Name = train_data.Name.astype('category')\n",
    "le_name = preprocessing.LabelEncoder()\n",
    "le_name.fit(list(train_data.Name)+list(test_data.Name))\n",
    "train_data.Name = le_name.transform(train_data.Name)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the Year and month from the timestamp column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:39:04.621920Z",
     "start_time": "2020-01-19T07:39:04.145757Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data['Year'] = pd.to_datetime(train_data.Timestamp).apply(lambda x: x.year)\n",
    "train_data['Month'] = pd.to_datetime(train_data.Timestamp).apply(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:39:05.119856Z",
     "start_time": "2020-01-19T07:39:05.093283Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defined a function process_decimal which will remove the comma, M(short hand for Million), K(short hand for Thousand) etc and process the deciaml values accordingly. \n",
    "\n",
    "## Applied the above function on Popularity and Likes columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:39:05.236129Z",
     "start_time": "2020-01-19T07:39:05.122348Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_decimal(x):\n",
    "    if x[-1].lower()=='k':\n",
    "        return pd.to_numeric(re.sub(\"[^0-9.]\", \"\", x))*1000\n",
    "    elif x[-1].lower()=='m':\n",
    "        return pd.to_numeric(re.sub(\"[^0-9.]\", \"\", x))*1000000\n",
    "    else:\n",
    "        return pd.to_numeric(re.sub(\"[^0-9.]\", \"\", x))\n",
    "    \n",
    "train_data.Popularity = pd.to_numeric(train_data.Popularity.apply(process_decimal))\n",
    "train_data.Likes = pd.to_numeric(train_data.Likes.apply(process_decimal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:39:10.386494Z",
     "start_time": "2020-01-19T07:39:10.366700Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculated the mean and variance of Views(Target Variable) with respect to each Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:39:10.602572Z",
     "start_time": "2020-01-19T07:39:10.389787Z"
    }
   },
   "outputs": [],
   "source": [
    "stats_genre = pd.DataFrame()\n",
    "stats_genre['genre_var'] = train_data.groupby(['Genre']).Views.var()\n",
    "stats_genre['genre_mean'] = train_data.groupby(['Genre']).Views.mean()\n",
    "stats_genre['genre_var'].fillna(stats_genre['genre_var'].mean(), inplace=True)\n",
    "stats_genre['genre_mean'].fillna(stats_genre['genre_mean'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculated the mean and variance of Views(Target Variable) with respect to each Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:39:10.683678Z",
     "start_time": "2020-01-19T07:39:10.604540Z"
    }
   },
   "outputs": [],
   "source": [
    "stats_name = pd.DataFrame()\n",
    "stats_name['name_mean'] = train_data.groupby(['Name']).Views.mean()\n",
    "stats_name['name_var'] = train_data.groupby(['Name']).Views.var()\n",
    "stats_name['name_mean'].fillna(stats_name['name_mean'].mean(), inplace=True)\n",
    "stats_name['name_var'].fillna(stats_name['name_var'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculated the mean and variance of Views(Target Variable) with respect to each Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:39:10.760694Z",
     "start_time": "2020-01-19T07:39:10.685518Z"
    }
   },
   "outputs": [],
   "source": [
    "stats_year = pd.DataFrame()\n",
    "stats_year['year_mean'] = train_data.groupby(['Year']).Views.mean()\n",
    "stats_year['year_var'] = train_data.groupby(['Year']).Views.var()\n",
    "stats_year['year_mean'].fillna(stats_year['year_mean'].mean(), inplace=True)\n",
    "stats_year['year_var'].fillna(stats_year['year_var'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:39:10.951112Z",
     "start_time": "2020-01-19T07:39:10.762415Z"
    }
   },
   "outputs": [],
   "source": [
    "stats_genre.head(), stats_genre.shape, stats_genre.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:39:11.057943Z",
     "start_time": "2020-01-19T07:39:10.961007Z"
    }
   },
   "outputs": [],
   "source": [
    "stats_name.head(), stats_name.shape, stats_name.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:39:11.186787Z",
     "start_time": "2020-01-19T07:39:11.060527Z"
    }
   },
   "outputs": [],
   "source": [
    "stats_year.head(), stats_year.shape, stats_year.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the calculated stats columns to the main dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:39:11.372250Z",
     "start_time": "2020-01-19T07:39:11.191639Z"
    }
   },
   "outputs": [],
   "source": [
    "join = train_data.merge(stats_genre, on='Genre',how='left').merge(stats_name, on='Name',how='left').merge(stats_year, on='Year',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for the nan cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:39:11.430402Z",
     "start_time": "2020-01-19T07:39:11.375455Z"
    }
   },
   "outputs": [],
   "source": [
    "join.shape, join.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop the columns which are not required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:39:11.487124Z",
     "start_time": "2020-01-19T07:39:11.432806Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = join.drop(['Unique_ID', 'Country', 'Timestamp', 'Song_Name'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperate the dependent column and independent column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:39:11.573394Z",
     "start_time": "2020-01-19T07:39:11.489472Z"
    }
   },
   "outputs": [],
   "source": [
    "Y = train_data.Views\n",
    "X = train_data.drop(['Views'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:39:11.761538Z",
     "start_time": "2020-01-19T07:39:11.575194Z"
    }
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Added two more composite features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:39:11.917787Z",
     "start_time": "2020-01-19T07:39:11.764696Z"
    }
   },
   "outputs": [],
   "source": [
    "X['feature_1'] = np.sqrt(X.Likes * X.Comments)\n",
    "X['feature_2'] = np.sqrt(X.name_mean * X.Comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:39:12.066314Z",
     "start_time": "2020-01-19T07:39:11.928177Z"
    }
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply PCA on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:39:12.327456Z",
     "start_time": "2020-01-19T07:39:12.069738Z"
    }
   },
   "outputs": [],
   "source": [
    "pca=PCA(n_components=3)\n",
    "pca_X = pca.fit_transform(X)\n",
    "print(pca_X.shape, X.shape)\n",
    "X = X.merge(pd.DataFrame(pca_X), how='left', left_index=True, right_index=True)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the explaned variance ration in order to calculate the number of components we need to have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:39:12.342228Z",
     "start_time": "2020-01-19T07:39:12.329974Z"
    }
   },
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:39:12.835417Z",
     "start_time": "2020-01-19T07:39:12.344075Z"
    }
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:41:24.606481Z",
     "start_time": "2020-01-19T07:39:12.842325Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'max_depth': 16, \n",
    "    'learning_rate': 0.01,\n",
    "    'verbose': 0, \n",
    "    'early_stopping_round': 1000,\n",
    "    'num_leaves':4096, \n",
    "    'max_bin':2048}\n",
    "params['metric'] = ['rmse']\n",
    "n_estimators = 3000\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(X,Y, test_size=0.10, random_state=1)\n",
    "d_train = lgb.Dataset(x_train, label=y_train)\n",
    "d_valid = lgb.Dataset(x_valid, label=y_valid)\n",
    "watchlist = [d_valid]\n",
    "\n",
    "model = lgb.train(params, d_train, n_estimators, watchlist, verbose_eval=1)\n",
    "\n",
    "preds = model.predict(x_valid)\n",
    "print(\"Val Loss:\", np.sqrt(np.sum(np.power(np.array(preds)-np.array(y_valid),2))/len(y_valid)))\n",
    "model_2 = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:43:01.552381Z",
     "start_time": "2020-01-19T07:41:24.616373Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Hyper parameter tunning\n",
    "# param_grid = {\n",
    "#           'n_estimators':[25, 50], \n",
    "#           'criterion':['mae', 'mse'],\n",
    "#           'max_depth':[8],\n",
    "#           'max_leaf_nodes':[50],\n",
    "#           'random_state':[1]\n",
    "#             }\n",
    "\n",
    "param_grid = {'criterion': ['mse'], 'n_estimators': [25], 'random_state': [1]}\n",
    "\n",
    "model=RandomForestRegressor()\n",
    "grid = GridSearchCV(estimator=model,\n",
    "                    param_grid=param_grid,\n",
    "#                     param_distributions=param_grid, n_iter=10,\n",
    "                    scoring=['r2', 'neg_mean_squared_error'],\n",
    "                    verbose=1,\n",
    "                    n_jobs=4,\n",
    "                    refit = 'neg_mean_squared_error',\n",
    "                    cv=5\n",
    "                   )\n",
    "grid_result = grid.fit(X, Y)\n",
    "\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)\n",
    "model_3 = grid.best_estimator_\n",
    "# Best Score:  -500903439391.60547\n",
    "# Best Params:  {'criterion': 'mse', 'n_estimators': 25, 'random_state': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:43:07.470762Z",
     "start_time": "2020-01-19T07:43:01.555379Z"
    }
   },
   "outputs": [],
   "source": [
    "#Hyper parameter tunning\n",
    "# param_grid = {\n",
    "#                 'n_neighbors':[10, 20, 30, 50, 100],\n",
    "#                 'algorithm':['auto', 'ball_tree', 'kd_tree'],\n",
    "#                 'p':[1, 2, 3, 4], \n",
    "#                 'weights':['uniform','distance'],\n",
    "#                 'n_jobs':[4]\n",
    "#              }\n",
    "\n",
    "param_grid = {'algorithm': ['auto'], 'n_jobs': [4], 'n_neighbors': [10], 'p': [2], 'weights': ['distance']}\n",
    "\n",
    "model=KNeighborsRegressor()\n",
    "grid = GridSearchCV(estimator=model,\n",
    "                    param_grid=param_grid,\n",
    "#                     param_distributions=param_grid, n_iter=10,\n",
    "                    scoring=['r2', 'neg_mean_squared_error'],\n",
    "                    verbose=1,\n",
    "                    n_jobs=4,\n",
    "                    refit = 'neg_mean_squared_error',\n",
    "                    cv=5\n",
    "                   )\n",
    "grid_result = grid.fit(X, Y)\n",
    "\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)\n",
    "model_4 = grid.best_estimator_\n",
    "# Best Score:  -9453498861626.154\n",
    "# Best Params:  {'algorithm': 'auto', 'n_jobs': 4, 'n_neighbors': 10, 'p': 2, 'weights': 'distance'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:44:50.190441Z",
     "start_time": "2020-01-19T07:43:07.473611Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'goss',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'max_depth': 16, \n",
    "    'learning_rate': 0.01,\n",
    "    'verbose': 0, \n",
    "    'early_stopping_round': 1000,\n",
    "    'num_leaves':2048, \n",
    "    'max_bin':2048}\n",
    "params['metric'] = ['rmse']\n",
    "n_estimators = 2000\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(X,Y, test_size=0.10, random_state=1)\n",
    "d_train = lgb.Dataset(x_train, label=y_train)\n",
    "d_valid = lgb.Dataset(x_valid, label=y_valid)\n",
    "watchlist = [d_valid]\n",
    "\n",
    "model = lgb.train(params, d_train, n_estimators, watchlist, verbose_eval=1)\n",
    "\n",
    "preds = model.predict(x_valid)\n",
    "print(\"Val Loss:\", np.sqrt(np.sum(np.power(np.array(preds)-np.array(y_valid),2))/len(y_valid)))\n",
    "model_5 = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T09:25:23.604052Z",
     "start_time": "2020-01-19T09:07:32.702016Z"
    }
   },
   "outputs": [],
   "source": [
    "#Hyper parameter tunning\n",
    "# param_grid = {'depth':[13,10],\n",
    "#           'iterations':[1000],\n",
    "#           'learning_rate':[0.01, 0.1], \n",
    "#           'l2_leaf_reg':[5,10],\n",
    "#           'border_count':[ 300],\n",
    "#           'ctr_border_count':[ 300],\n",
    "#           'random_state':[1]}\n",
    "\n",
    "param_grid = {'border_count': [200], 'ctr_border_count': [200], 'depth': [12], 'iterations': [1000], 'l2_leaf_reg': [5], 'learning_rate': [0.01], 'random_state': [1]}\n",
    "\n",
    "cat_feats=[0,1,6,7]\n",
    "\n",
    "model=catboost.CatBoostRegressor(cat_features=cat_feats)\n",
    "grid = GridSearchCV(estimator=model,\n",
    "                    param_grid=param_grid,\n",
    "#                     param_distributions=param_grid, n_iter=10,\n",
    "                    scoring=['r2', 'neg_mean_squared_error'],\n",
    "                    verbose=1,\n",
    "                    n_jobs=4,\n",
    "                    refit = 'neg_mean_squared_error',\n",
    "                    cv=5\n",
    "                   )\n",
    "grid_result = grid.fit(X, Y)\n",
    "\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)\n",
    "model_1 = grid.best_estimator_\n",
    "# Best Score:  -2186169917327.6897\n",
    "# Best Params:  {'border_count': 200, 'ctr_border_count': 200, 'depth': 12, 'iterations': 1000, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'random_state': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XG Boost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T08:03:10.440462Z",
     "start_time": "2020-01-19T08:02:02.469482Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# param_grid = {'min_child_weight':[1, 2, 4,5], 'gamma':[i/10.0 for i in range(3,6)],  'subsample':[i/10.0 for i in range(6,11)],\n",
    "# 'colsample_bytree':[i/10.0 for i in range(6,11)], 'max_depth': [2,3,4,5,8,11], 'random_state':[1]}\n",
    "\n",
    "param_grid={'colsample_bytree': [0.7], 'gamma': [0.3], 'max_depth': [11], 'min_child_weight': [4], 'random_state': [1], 'subsample': [0.8]}\n",
    "\n",
    "model = XGBRegressor()\n",
    "grid = GridSearchCV(estimator=model,\n",
    "                    param_grid=param_grid,\n",
    "#                     param_distributions=param_grid, n_iter=10,\n",
    "                    scoring=['r2', 'neg_mean_squared_error'],\n",
    "                    verbose=1,\n",
    "                    n_jobs=4,\n",
    "                    refit = 'neg_mean_squared_error',\n",
    "                    cv=5\n",
    "                   )\n",
    "grid_result = grid.fit(X, Y)\n",
    "\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)\n",
    "model_6 = grid.best_estimator_\n",
    "preds = model_6.predict(x_valid)\n",
    "print(\"Val Loss:\", np.sqrt(np.sum(np.power(np.array(preds)-np.array(y_valid),2))/len(y_valid)))\n",
    "# Best Score:  -359030292377.03534\n",
    "# Best Params:  {'colsample_bytree': 0.7, 'gamma': 0.3, 'max_depth': 11, 'min_child_weight': 4, 'random_state': 1, 'subsample': 0.8}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T08:03:10.464065Z",
     "start_time": "2020-01-19T08:03:10.443040Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T08:03:10.616038Z",
     "start_time": "2020-01-19T08:03:10.466814Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the Genre column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T08:03:10.783300Z",
     "start_time": "2020-01-19T08:03:10.618443Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data.Genre = test_data.Genre.astype('category')\n",
    "test_data.Genre = le_genre.transform(test_data.Genre)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the Name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T08:03:10.820380Z",
     "start_time": "2020-01-19T08:03:10.786431Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data.Name = test_data.Name.astype('category')\n",
    "test_data.Name = le_name.transform(test_data.Name)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T08:03:10.889726Z",
     "start_time": "2020-01-19T08:03:10.824866Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the Year & Month from timestamp column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T08:03:11.207226Z",
     "start_time": "2020-01-19T08:03:10.892365Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data['Year'] = pd.to_datetime(test_data.Timestamp).apply(lambda x: x.year)\n",
    "test_data['Month'] = pd.to_datetime(test_data.Timestamp).apply(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T08:03:11.359263Z",
     "start_time": "2020-01-19T08:03:11.327416Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the columns Likes & Popularity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T08:03:12.776596Z",
     "start_time": "2020-01-19T08:03:11.361738Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data.Popularity = pd.to_numeric(test_data.Popularity.apply(process_decimal))\n",
    "test_data.Likes = pd.to_numeric(test_data.Likes.apply(process_decimal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T08:03:12.806652Z",
     "start_time": "2020-01-19T08:03:12.777950Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append the stats columns calculated with the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T08:03:13.094530Z",
     "start_time": "2020-01-19T08:03:12.812337Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = test_data.merge(stats_genre, on='Genre',how='left').merge(stats_name, on='Name',how='left').merge(stats_year, on='Year',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the columns which aren't required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T08:03:13.148671Z",
     "start_time": "2020-01-19T08:03:13.097511Z"
    }
   },
   "outputs": [],
   "source": [
    "test_ids = test_data.Unique_ID\n",
    "test_data = test_data.drop(['Unique_ID', 'Country', 'Timestamp', 'Song_Name'], axis=1)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace the nan with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T08:03:13.204488Z",
     "start_time": "2020-01-19T08:03:13.151286Z"
    }
   },
   "outputs": [],
   "source": [
    "print(test_data.isna().sum().sum())\n",
    "test_data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T08:03:13.378258Z",
     "start_time": "2020-01-19T08:03:13.287034Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the two new compound columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T08:03:13.456481Z",
     "start_time": "2020-01-19T08:03:13.382080Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data['feature_1'] = np.sqrt(test_data.Likes * test_data.Comments)\n",
    "test_data['feature_2'] = np.sqrt(test_data.name_mean * test_data.Comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T08:03:13.552110Z",
     "start_time": "2020-01-19T08:03:13.459777Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply PCA on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T08:03:13.644776Z",
     "start_time": "2020-01-19T08:03:13.555187Z"
    }
   },
   "outputs": [],
   "source": [
    "pca_X = pca.transform(test_data)\n",
    "print(pca_X.shape, test_data.shape)\n",
    "test_data = test_data.merge(pd.DataFrame(pca_X), how='left', left_index=True, right_index=True)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T08:03:13.755263Z",
     "start_time": "2020-01-19T08:03:13.648136Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T08:03:13.844624Z",
     "start_time": "2020-01-19T08:03:13.757930Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T08:03:13.929100Z",
     "start_time": "2020-01-19T08:03:13.857062Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the Views for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T08:03:14.216713Z",
     "start_time": "2020-01-19T08:03:13.931944Z"
    }
   },
   "outputs": [],
   "source": [
    "# y_test_1 = model_1.predict(test_data)\n",
    "# y_test_2 = model_2.predict(test_data)\n",
    "# y_test_3 = model_3.predict(test_data)\n",
    "# y_test_4 = model_4.predict(test_data)\n",
    "# y_test_5 = model_5.predict(test_data)\n",
    "y_test_6 = model_6.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Excel file to submit the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T08:03:14.403971Z",
     "start_time": "2020-01-19T07:39:01.758Z"
    }
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results['Unique_ID'] = test_ids\n",
    "results['Views'] = y_test_6\n",
    "results.Views = results.Views.apply(lambda x: np.abs(x))\n",
    "results.to_excel('results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank: 34 \n",
    "# LeaderBoard Score: 674507.59773"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
